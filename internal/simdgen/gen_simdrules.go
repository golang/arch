// Copyright 2025 The Go Authors. All rights reserved.
// Use of this source code is governed by a BSD-style
// license that can be found in the LICENSE file.

package main

import (
	"fmt"
	"sort"
)

const simdrulesTmpl = `// Code generated by x/arch/internal/simdgen using 'go run . -xedPath $XED_PATH -o godefs -goroot $GOROOT go.yaml types.yaml categories.yaml'; DO NOT EDIT.

// The AVX instruction encodings orders vector register from right to left, for example:
// VSUBPS X Y Z means Z=Y-X
// The rules here swapped the order of such X and Y because the ssa to prog lowering in simdssa.go assumes a
// left to right order.
// TODO: we should offload the logic to simdssa.go, instead of here.
//
// Masks are always at the end, immediates always at the beginning.

{{- range .Ops }}
{{if eq (len .In) 1}}({{.Go}}{{(index .In 0).Go}} x) => ({{.Asm}} x){{end}}{{if eq (len .In) 2}}({{.Go}}{{(index .In 0).Go}} x y) => ({{.Asm}} y x){{end}}
{{- end }}
{{- range .OpsImm }}
({{.Go}}{{(index .In 1).Go}} x y) => ({{.Asm}} [{{(index .In 0).Const}}] y x)
{{- end }}
{{- range .OpsMask}}
({{.Go}}{{(index .In 0).Go}} x y z) => ({{.Asm}} y x (VPMOVVec{{(index .In 0).ElemBits}}x{{(index .In 0).Lanes}}ToM <types.TypeMask> z))
{{- end }}
{{- range .OpsImmMask}}
({{.Go}}{{(index .In 1).Go}} x y z) => ({{.Asm}} [{{(index .In 0).Const}}] y x (VPMOVVec{{(index .In 1).ElemBits}}x{{(index .In 1).Lanes}}ToM <types.TypeMask> z))
{{- end }}
{{- range .OpsMaskOut}}
({{.Go}}{{(index .In 0).Go}} x y) => (VPMOVMToVec{{(index .In 0).ElemBits}}x{{(index .In 0).Lanes}} ({{.Asm}} y x))
{{- end }}
{{- range .OpsImmInMaskOut}}
({{.Go}}{{(index .In 1).Go}} x y) => (VPMOVMToVec{{(index .In 1).ElemBits}}x{{(index .In 1).Lanes}} ({{.Asm}} [{{(index .In 0).Const}}] y x))
{{- end }}
{{- range .OpsMaskInMaskOut}}
({{.Go}}{{(index .In 0).Go}} x y z) => (VPMOVMToVec{{(index .In 0).ElemBits}}x{{(index .In 0).Lanes}} ({{.Asm}} y x (VPMOVVec{{(index .In 0).ElemBits}}x{{(index .In 0).Lanes}}ToM <types.TypeMask> z)))
{{- end }}
{{- range .OpsImmMaskInMaskOut}}
({{.Go}}{{(index .In 1).Go}} x y z) => (VPMOVMToVec{{(index .In 1).ElemBits}}x{{(index .In 1).Lanes}} ({{.Asm}} [{{(index .In 0).Const}}] y x (VPMOVVec{{(index .In 1).ElemBits}}x{{(index .In 1).Lanes}}ToM <types.TypeMask> z)))
{{- end }}
`

// writeSIMDRules generates the lowering and rewrite rules for ssa and writes it to simdAMD64.rules
// within the specified directory.
func writeSIMDRules(directory string, ops []Operation) error {
	file, t, err := openFileAndPrepareTemplate(directory, "src/cmd/compile/internal/ssa/_gen/simdAMD64.rules", simdrulesTmpl)
	if err != nil {
		return err
	}
	defer file.Close()
	Ops := make([]Operation, 0)
	OpsImm := make([]Operation, 0)
	OpsMask := make([]Operation, 0)
	OpsImmMask := make([]Operation, 0)
	OpsMaskOut := make([]Operation, 0)
	OpsImmInMaskOut := make([]Operation, 0)
	OpsMaskInMaskOut := make([]Operation, 0)
	OpsImmMaskInMaskOut := make([]Operation, 0)

	for _, op := range ops {
		opInShape, opOutShape, maskType, _, op, _, err := op.shape()
		if err != nil {
			return err
		}
		if maskType == OneMask {
			op.Asm += "Masked"
		}
		op.Asm = fmt.Sprintf("%s%d", op.Asm, *op.Out[0].Bits)
		// If class overwrite is happening, that's not really a mask but a vreg.
		if opOutShape == OneVregOut || op.Out[0].OverwriteClass != nil {
			switch opInShape {
			case PureVregIn:
				Ops = append(Ops, op)
			case OneKmaskIn:
				OpsMask = append(OpsMask, op)
			case OneConstImmIn:
				OpsImm = append(OpsImm, op)
			case OneKmaskConstImmIn:
				OpsImmMask = append(OpsImmMask, op)
			case PureKmaskIn:
				return fmt.Errorf("simdgen does not support pure k mask instructions, they should be generated by compiler optimizations")
			}
		} else {
			// OneKmaskOut case
			switch opInShape {
			case PureVregIn:
				OpsMaskOut = append(OpsMaskOut, op)
			case OneKmaskIn:
				OpsMaskInMaskOut = append(OpsMaskInMaskOut, op)
			case OneConstImmIn:
				OpsImmInMaskOut = append(OpsImmInMaskOut, op)
			case OneKmaskConstImmIn:
				OpsImmMaskInMaskOut = append(OpsImmMaskInMaskOut, op)
			case PureKmaskIn:
				return fmt.Errorf("simdgen does not support pure k mask instructions, they should be generated by compiler optimizations")
			}
		}
	}
	sortKey := func(op *Operation) string {
		return *op.In[0].Go + op.Go
	}
	sortBySortKey := func(ops []Operation) {
		sort.Slice(ops, func(i, j int) bool {
			return sortKey(&ops[i]) < sortKey(&ops[j])
		})
	}
	sortBySortKey(Ops)
	sortBySortKey(OpsImm)
	sortBySortKey(OpsMask)
	sortBySortKey(OpsImmMask)
	sortBySortKey(OpsMaskOut)
	sortBySortKey(OpsImmInMaskOut)
	sortBySortKey(OpsMaskInMaskOut)
	sortBySortKey(OpsImmMaskInMaskOut)

	type templateData struct {
		Ops                 []Operation
		OpsImm              []Operation
		OpsMask             []Operation
		OpsImmMask          []Operation
		OpsMaskOut          []Operation
		OpsImmInMaskOut     []Operation
		OpsMaskInMaskOut    []Operation
		OpsImmMaskInMaskOut []Operation
	}

	err = t.Execute(file, templateData{
		Ops,
		OpsImm,
		OpsMask,
		OpsImmMask,
		OpsMaskOut,
		OpsImmInMaskOut,
		OpsMaskInMaskOut,
		OpsImmMaskInMaskOut})
	if err != nil {
		return fmt.Errorf("failed to execute template: %w", err)
	}

	return nil
}
